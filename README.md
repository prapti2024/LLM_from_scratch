# ğŸ§  LLM from Scratch

This project is a minimal and educational implementation of a Generative Pre-trained Transformer (GPT) model, inspired by the paper *â€œAttention is All You Needâ€* and projects like Karpathy's `minGPT`.

The goal is to build a GPT-style language model **entirely from scratch**, without relying on high-level libraries like HuggingFace. This serves as a hands-on exercise to understand the inner workings of LLMs â€” including tokenization, transformer blocks, attention mechanisms, and training dynamics.

---

## ğŸš€ Features

- Character-level tokenizer  
- Custom embedding layers  
- Multi-head self-attention  
- Layer normalization and residual connections  
- GPT-style decoder-only transformer architecture  
- Training loop using cross-entropy loss  
- Sample generation from trained model

---
 

## ğŸ“ Repository Structure

`````

LLM_from_scratch/
â”œâ”€â”€ gpt_from_scratch.ipynb   # Main notebook: build and train GPT step by step
â”œâ”€â”€ README.md     # Project overview and documentation

 `````

---

## ğŸ› ï¸ Requirements

- Python 3.8+  
- PyTorch  
- NumPy  
- tqdm (for progress bar)

Install dependencies:

```bash
pip install torch numpy tqdm
```
ğŸ§ª How to Run

Clone the repo:
```
git clone https://github.com/prapti2024/LLM_from_scratch.git
cd LLM_from_scratch
```
Open the Jupyter notebook:
```
jupyter notebook gpt_from_scratch.ipynb
```

Run cells step-by-step to build the model, train it on a small dataset (like Shakespeare), and generate text samples.

---
## ğŸ“Š Training Example

The model is trained on a small text corpus using character-level prediction. Here's an example of generated text after training:

```css
Whathasth be thas areson all,
Yoe milde sape spank bores.
```
(Yes, itâ€™s gibberish, but it demonstrates learned patterns of structure and punctuation!)

---

## ğŸ“š Inspiration

Sebastian Raschka
(Build a LLM from Scratch)

---

## âœ… TODO

Add positional encodings (sinusoidal/trainable)

Switch to BPE or WordPiece tokenizer

Train on larger datasets

Save and reload model checkpoints

---

## ğŸ§‘â€ğŸ’» Author

Prapti Dahal

GitHub

---
